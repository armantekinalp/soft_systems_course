{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algorithms using `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demonstration, we will code up step-by-step, a simple GA for optimizing a trivial function with constraints. Further exploration in this example would be very useful for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Do some Ipython black magic\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "We need to maximize the function  $ f(\\mathbf{x}) = \\sum_{i=1}^{6} w_i x_i $ for a given set of weights $ w_i $, with the constraints that $ x_i \\; \\in \\; [-4,4] \\; \\forall \\; i$. This means that the domain $\\mathbb{D}$ of the search is $ \\mathbb{D}:= [-4,4]^6$. The optimization problem can be succinctly represented as $\\left(\\mathbb{D}, \\mathbb{R} , \\mathbf{f}, \\geq \\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ease of solving the problem\n",
    "\n",
    "We note that this example is trivial because given a set of weights, we need to pick either $x_i=-4$ or $x_i=4$ as the objective function is linear. That's precisely the point however, as we know the solution to the problem, and we can compare how GA performs (as a search algorithm in itself, and against design parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given\n",
    "The weight vector $\\mathbf{w} = [6,8,-6,3,3,-4]$. For this case then, the optimal solution is $\\mathbf{x}^* = [4, 4, -4, 4, 4, -4]$ which gives a maximum possible objective value $f^* = 120$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WEIGHTS = 6 # Helper variable\n",
    "WEIGHTS = np.array([6,8,-6,3,3,-4], dtype = np.float64) # Optional dtype argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the shape so that we are happy\n",
    "np.shape(WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you want to encode this problem? To keep the demonstration simple, we pick a set of 6 floating point numbers (as a `numpy` array) directly. We need to keep in mind that variation needs to be done on this representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can define my optimal solution vector now, since I have decided my representation\n",
    "X_STAR = np.array([4, 4, -4, 4, 4, -4], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have picked representation, let's start off the problem. We need to pick a population size (i.e. number of parents in the initial generation). Let's pick a nice number, say 10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the population\n",
    "POP_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember! Each member of this population is a vector with shape `(6,)`. Is there a way to efficiently represent/generate/work with this entire population all at one go?\n",
    "\n",
    "Of course! Put them together as a 2 dimensional array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper variable that generates POP_SIZE x NUM_WEIGHTS population\n",
    "DOFS_IN_POP = (POP_SIZE, N_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population will have `POP_SIZE` chromosomes where each chromosome has `NUM_WEIGHTS` genes. Let's generate the initial population that our GA algorithm will work on. This population needs to be randomly initialized, say around $0.0$. The `numpy.random` module comes to mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_population = np.random.uniform(low=-4.0, high=4.0, size=DOFS_IN_POP)\n",
    "# What about these guys?\n",
    "# curr_population = np.random.uniform?\n",
    "# curr_population = np.random.random_sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness assignment\n",
    "In this demo, we assign fitness directly using the objective function (without penalty, we'll deal with constraints later on). However you can best decide what fitness works for your problem (competitive? informal?...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(t_pop):\n",
    "    \"\"\" Calculates fitness given the population using global weights\n",
    "    The fitness function calulates the sum of products between each input and its corresponding weight.\n",
    "    Returns a (POP_SIZE, ) numpy array\n",
    "    \"\"\"        \n",
    "    # Do elementwise across columns, then sum the columns up together\n",
    "    # fitness = np.sum(t_pop * WEIGHTS, axis=1)\n",
    "\n",
    "    # Do a matrix vector multiply of (10,6) * (6,)\n",
    "    fitness = t_pop @ WEIGHTS\n",
    "\n",
    "    # There are other ways to do the same thing, but why would you?\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_fitness = calc_fitness(curr_population)\n",
    "print(my_fitness.shape)\n",
    "print(my_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection for variation\n",
    "\n",
    "### How do you select parents to spread their genes? \n",
    "One way to do it is to select *best* parents only to mate. This is an example of a **determinstic selection scheme**, wherein we rank them by fitness and consider the best ones.\n",
    "\n",
    "### How many parents to select for mating? \n",
    "This is up to the user. Some people prefer to use heuristics based on the population size for determining the mating pool size. Sometimes it depends on the selection scheme used (for example, in tournament selection where the $T$ parameter, along with the population size determines the mating pool size).\n",
    "\n",
    "For simplicity in this demo, let's fix the number of parents that are selected to mate at every iteration and store it as a variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MATING = 4\n",
    "\n",
    "def select_determinstic(t_pop, t_fitness):\n",
    "    \"\"\" Given current population t_pop, select N_MATING number of parents using determinstic selection scheme\n",
    "    based on t_fitness \n",
    "\n",
    "    Returns parents and their fitness (just because)\n",
    "    \"\"\"\n",
    "    # Returns sorting indices, based on max fitness\n",
    "    # Arranged from min-> max fitness\n",
    "    idx = np.argsort(t_fitness)\n",
    "    # Now its max fitness on top and min on bottom\n",
    "    idx = idx[::-1]\n",
    "\n",
    "    # Sort parents according to the index\n",
    "    parents = t_pop[idx]\n",
    "\n",
    "    # Select best parents\n",
    "    parents = parents[:N_MATING, :]\n",
    "    return (parents, calc_fitness(parents))\n",
    "\n",
    "    \n",
    "    ''' If you don't want to reverse, you can do the following\n",
    "    '''\n",
    "#     # Returns sorting indices, based on max fitness\n",
    "#     # Arranged from min-> max fitness\n",
    "#     idx = np.argsort(t_fitness)\n",
    "\n",
    "#     # Select parents according to the index\n",
    "#     parents = t_pop[idx]\n",
    "\n",
    "#     # Select best parents\n",
    "#     parents = parents[-N_MATING:, :]\n",
    "#     return (parents, calc_fitness(parents))\n",
    "\n",
    "    \n",
    "    '''You can also do it in a convoluted way like below, but I don't recommend it\n",
    "    Always code like some other person is watching you code''' \n",
    "\n",
    "#     # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "#     parents = numpy.empty((num_parents, pop.shape[1]))\n",
    "#     for parent_num in range(num_parents):\n",
    "#         max_fitness_idx = numpy.where(fitness == numpy.max(fitness))\n",
    "#         max_fitness_idx = max_fitness_idx[0][0]\n",
    "#         parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "#         fitness[max_fitness_idx] = -99999999999\n",
    "#     return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parents, my_parents_fit = select_determinstic(curr_population, my_fitness)\n",
    "my_parents\n",
    "my_parents_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you show me an example of stochastic selection?\n",
    "\n",
    "Let's implement Stochastic Universal Sampling, which consists of\n",
    "\n",
    "* Sampling rate assignment\n",
    "* Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_stochastic(t_pop, t_fitness):\n",
    "    \"\"\" Given current population t_pop, select N_MATING number of parents using SUS\n",
    "    based on t_fitness \n",
    "\n",
    "    Returns parents and their fitness (just because)\n",
    "    \"\"\"\n",
    "\n",
    "    ''' Sampling rate assignment using linear rank-based sampling\n",
    "    '''\n",
    "    # Rank based on max fitness\n",
    "    # Arranged from min-> max fitness\n",
    "    # Do the same for parents later on\n",
    "    idx = np.argsort(t_fitness)\n",
    "\n",
    "    # Copied shamelessly from https://stackoverflow.com/a/5284703\n",
    "    r_i = np.empty_like(idx)\n",
    "    r_i[idx] = np.arange(len(t_fitness))\n",
    " \n",
    "    # Same as \n",
    "    # r_i = np.argsort(idx)\n",
    "\n",
    "    \"\"\"\n",
    "        >>> t_fitness\n",
    "        >>> array([-18.29817097,  22.688013  ,  65.55614464, -22.39372802,\n",
    "           -11.53236791,  40.55497738, -13.77672983,  14.9189356 ,\n",
    "            60.09509336,  32.67900684])\n",
    "\n",
    "        >>> idx\n",
    "        >>> [3 0 6 4 7 1 9 5 8 2]\n",
    "\n",
    "        >>> r_i\n",
    "        >>> [1 5 9 0 3 7 2 4 8 6]\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate linear weighting with alpha = 2\n",
    "    p_i = r_i + 2\n",
    "\n",
    "    # Calculate q_i as an avverage measure of p_i\n",
    "    sum_pi = np.sum(p_i)\n",
    "    q_i = p_i / sum_pi\n",
    "\n",
    "    # Rank from biggest to least for ease of use\n",
    "    q_idx = np.argsort(q_i)\n",
    "\n",
    "    # Regular q_i is for t_pop\n",
    "    # The sorted q_i is now for (t_pop)[q_idx]\n",
    "    # The reversed q_i is then for ((t_pop)[q_idx])[::-1]\n",
    "    \n",
    "    q_i = q_i[q_idx]\n",
    "    q_i = q_i[::-1]\n",
    "\n",
    "\n",
    "    ''' With this sampling rate q_i pick up four parents\n",
    "    '''\n",
    "    # Increment to generated random number\n",
    "    random_increment = 1./N_MATING\n",
    "\n",
    "    # Generate a random number\n",
    "    random_val = np.random.rand(1, )\n",
    "\n",
    "    # Select four zones of q_i to select\n",
    "    arrow_locations = random_val + random_increment * np.arange(N_MATING)\n",
    "    \"\"\"    \n",
    "        >>> arrow_locations\n",
    "        >>> [0.52196859 0.77196859 1.02196859 1.27196859]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure it stays within 1\n",
    "    arrow_locations %= 1\n",
    "    \"\"\"    \n",
    "        >>> arrow_locations\n",
    "        >>> [0.52196859 0.77196859 0.02196859 0.27196859]\n",
    "    \"\"\"\n",
    "\n",
    "    # In place sorting to get (r, r+1/N_MATING, r + 2/N_MATING ...., r + (N_MATING-1)/N_MATING)\n",
    "    arrow_locations.sort()\n",
    "    \"\"\"    \n",
    "        >>> arrow_locations\n",
    "        >>> [0.02196859 0.27196859 0.52196859 0.77196859]\n",
    "    \"\"\"\n",
    "\n",
    "    # Based on arrow locations, pick the parents\n",
    "    cum_qi = np.cumsum(q_i)\n",
    "    \"\"\"    \n",
    "        >>> cum_qi\n",
    "        >>> [0.16923077 0.32307692 0.46153846 0.58461538 0.69230769 0.78461538\n",
    "     0.86153846 0.92307692 0.96923077 1.        ]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Where do you find the arrows within cum_qi\n",
    "    zone_belong = np.searchsorted(cum_qi, arrow_locations)\n",
    "    # print(zone_belong)\n",
    "    \"\"\"    \n",
    "        >>> zone_belong\n",
    "        >>> [0 1 3 5]\n",
    "    \"\"\"\n",
    "\n",
    "    # zone_belong returns index of individuals in the max-->min list \n",
    "    # I want indices in the min--> max list\n",
    "    # One hacky way of doing this is just do a size-1 subtraction\n",
    "    zone_belong = POP_SIZE - zone_belong - 1\n",
    "    \n",
    "    # The q_i of the selected indviduals\n",
    "    parents = t_pop[q_idx][zone_belong]\n",
    "    par_fitness = t_fitness[q_idx][zone_belong]\n",
    "\n",
    "    return (parents, par_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parents, my_par_fitness = select_stochastic(curr_population, my_fitness)\n",
    "my_parents\n",
    "my_par_fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variation\n",
    "Variation has two operations : crossover/recombination (produce new offspring from the parents selected in the prior step) and mutation (produced mutated/randomly offset offspring). Let's see each one separately.\n",
    "\n",
    "### Recombination\n",
    "For this demonstration, lets do a one-point crossover. This means we naively *mix* the solution vectors---we take some  components (among the six) from one parent and the rest from another parent... \n",
    "\n",
    "Before proceeding, we want to determine the limit of offspring vectors to be produced. This has to be a reasonable number and should depend on the population and the number of parents selected for mating. This also corresponds to the $\\lambda$ deterministic selection schemes.\n",
    "\n",
    "We also need to select $p_c$, the crossover rate---it determines the probability of a crossover happening between two parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OFFSPRING = 3\n",
    "IDX_CROSSOVER = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our demo, let's fix $p_c$ to 1 (recombination happens always). We also fixed the offspring size above to $0.5 \\cdot {\\text{N_MATING}\\choose 2} = 3$. This allows every selected parent to propogate their genes. The parent vectors are chosen in a fixed fashion (1 mates with 2, 2 with 3 and so on...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where to crossover? Sometimes we use an additional random integer (respecting array range constraints) that determines at which location a crossover should occur. In our example below, let's perform a *uniform* one-point crossover (uniform in the sense that we always do crossover at a selected index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(t_parents):\n",
    "    \"\"\" Given a set of parents, combine them and return offspring vectors\n",
    "    \n",
    "    Returns the offsprings and their fitness\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an emppty vector\n",
    "    offspring = np.empty((N_OFFSPRING, N_WEIGHTS))\n",
    "\n",
    "    for k in range(N_OFFSPRING):\n",
    "        # We do % N_MATING in case it goes out of range\n",
    "        \n",
    "        # Index of the first parent to mate.\n",
    "        p1_idx = k%N_MATING\n",
    "\n",
    "        # Index of the second parent to mate.\n",
    "        p2_idx = (k+1)%N_MATING\n",
    "        \n",
    "        # The new offspring will have its first half of its genes taken from the first parent.\n",
    "        offspring[k, :IDX_CROSSOVER] = t_parents[p1_idx, :IDX_CROSSOVER]\n",
    "\n",
    "        # The new offspring will have its second half of its genes taken from the second parent.\n",
    "        offspring[k, IDX_CROSSOVER:] = t_parents[p2_idx, IDX_CROSSOVER:]\n",
    "\n",
    "    return (offspring, calc_fitness(offspring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does crossover create new offspring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_offspring,  my_offspring_fitness = crossover(my_parents)\n",
    "my_parents\n",
    "my_offspring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does! Are the offsprings fitter than their parents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_par_fitness\n",
    "my_offspring_fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are! This is good news..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation\n",
    "For this demonstration, lets add uniform random numbers drawn between $[-0.5, 0.5)$ to the offspring. But let's not do it everytime---we will do that with a probability $p_m = 0.5$, sampled for each offspring. Recollect that this is the mutation rate parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM = 0.5\n",
    "def mutation(t_offspring):\n",
    "    \"\"\" Given a set of offsprings, introduce mutation in them\n",
    "   \n",
    "    Returns the mutated offsprings and their fitness\n",
    "    \"\"\"\n",
    "\n",
    "    # Mutation changes all genes in each offspring randomly.\n",
    "    # You can also code for a single gene, single gene with some probability and so on...\n",
    "\n",
    "    # Generate a random number in [0, 1) to mutate each offspring\n",
    "    random_mutator = np.random.uniform(0.0, 1.0, (N_OFFSPRING,))\n",
    "\n",
    "    # Check where the random_mutator is > PM\n",
    "    # Gives true in those places\n",
    "    idx = random_mutator > PM\n",
    "\n",
    "    # Count number of trues in the above condition\n",
    "    nnz = np.count_nonzero(idx)\n",
    "\n",
    "    # Copy just for comparison of offspring before and after mutation\n",
    "    # You can remove if efficiency is a concern\n",
    "    mutated_offspring = t_offspring.copy()\n",
    "\n",
    "    # For true idx, add randomly sampled vector in [-0.5, 0.5)\n",
    "    # print(random_mutator, idx)\n",
    "    mutated_offspring[idx] += np.random.uniform(-0.5, 0.5, (nnz, N_WEIGHTS))\n",
    "    \n",
    "    return (mutated_offspring, calc_fitness(mutated_offspring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we see some mutation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mut_offspring, my_mut_offspring_fitness = mutation(my_offspring)\n",
    "my_offspring\n",
    "my_mut_offspring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental selection\n",
    "The final step is environmental selection. This comes in two parts:\n",
    "\n",
    "1) Imposing any hard constraints, such as those violating range being chucked out\n",
    "\n",
    "2) Picking the `POP_SIZE` best individuals and sending them to the next generation\n",
    "\n",
    "\n",
    "\n",
    "Let's first throw out any individuals not adhering to the limits set by or constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_constraint(t_total_pop):\n",
    "    \"\"\" Scans the array for individual violating constraint bounds\n",
    "    and chucks them out of processing\n",
    "\n",
    "    t_all includes all vectors (parents + mutated offsprings)\n",
    "    \"\"\"\n",
    "    idx1 = (t_total_pop >= -4.0)\n",
    "    idx2 = (t_total_pop <= 4.0)\n",
    "\n",
    "    # And condition as both must be satisfied\n",
    "    idx = idx1 & idx2\n",
    "\n",
    "    # Returns an entire row as false even if one evaluares to False\n",
    "    # The axis argument tells along which axis it should scan\n",
    "    idx = np.all(idx, axis=1)\n",
    "\n",
    "    return t_total_pop[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the constraint check passes. Let's concatenate all vectors into one big unit and do constraint check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing constraints \n",
    "# Group curr_population, my_parents, my_mut_offspring here\n",
    "# Stack them one top of another\n",
    "total_population = np.vstack((curr_population, my_mut_offspring))\n",
    "\n",
    "# Verify shape\n",
    "total_population.shape\n",
    "\n",
    "total_population = hard_constraint(total_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then pick the top `POP_SIZE` individuals next, based on their fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def environmental_selection(t_total_pop):\n",
    "    \"\"\" Calculate total population (after constraint checking) fitness,\n",
    "    rank accoridingly and select only the top POP_SIZE individuals to\n",
    "    pass on to the next generation\n",
    "    \"\"\" \n",
    "\n",
    "    tot_fitness = calc_fitness(t_total_pop)\n",
    "    \n",
    "    # Calculate elements from small->top fitness\n",
    "    idx = np.argsort(tot_fitness)\n",
    "    \n",
    "    # Reverse to give top->small fitness\n",
    "    idx = idx[::-1]\n",
    "    \n",
    "    # Cut off POP_SIZE elements\n",
    "    idx = idx[:POP_SIZE]\n",
    "\n",
    "    # Return corresponding population\n",
    "    return t_total_pop[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether selecting top 10 works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before\")\n",
    "total_population.shape\n",
    "calc_fitness(total_population)\n",
    "new_population = environmental_selection(total_population)\n",
    "print(\"After\")\n",
    "new_population.shape\n",
    "calc_fitness(new_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's hook them all up together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add some utilities to help us track progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_outputs = []\n",
    "num_generations = 1000\n",
    "curr_population = np.random.uniform(low=-4.0, high=4.0, size=DOFS_IN_POP)\n",
    "overall_max_fitness = -99999\n",
    "\n",
    "# Run many iterations\n",
    "# You should also have another convergence check\n",
    "for generation in range(num_generations):\n",
    "    print(\"Generation : \", generation)\n",
    "\n",
    "    # Measuring the fitness of each chromosome in the population.\n",
    "    fitness = calc_fitness(curr_population)\n",
    "\n",
    "    # print(\"Fitness\")\n",
    "    # print(fitness)\n",
    "\n",
    "    max_fitness = np.max(fitness)\n",
    "\n",
    "    # The best result in the current iteration.\n",
    "    print(\"Best result in current iteration {0} compared to overall {1}\".format(max_fitness, max(max_fitness, overall_max_fitness)))\n",
    "    best_outputs.append(max_fitness)\n",
    "    \n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents, _ = select_determinstic(curr_population, fitness)\n",
    "#     parents, _ = select_stochastic(curr_population, fitness)\n",
    "    \n",
    "    # print(\"Parents\")\n",
    "    # print(parents)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossed, _ = crossover(parents)\n",
    "\n",
    "    # print(\"Crossover\")\n",
    "    # print(offspring_crossover)\n",
    "\n",
    "    # Adding some variations to the offspring using mutation.\n",
    "    offspring_mutated, _ = mutation(offspring_crossed)\n",
    "\n",
    "    # print(\"Mutation\")\n",
    "    # print(offspring_mutation)\n",
    "\n",
    "    # Check for constraints\n",
    "    total_population = np.vstack((curr_population, offspring_mutated))\n",
    "    total_population = hard_constraint(total_population)\n",
    "\n",
    "    # Environmental selection\n",
    "    curr_population = environmental_selection(total_population)\n",
    "              \n",
    "# Getting the best solution after iterating finishing all generations.\n",
    "#At first, the fitness is calculated for each solution in the final generation.\n",
    "fitness = calc_fitness(curr_population)\n",
    "\n",
    "# Then return the index of that solution corresponding to the best fitness.\n",
    "max_idx = np.argmax(fitness)\n",
    "\n",
    "print(\"Best solution : \", new_population[max_idx, :])\n",
    "print(\"Best solution fitness : \", fitness[max_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our GA performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(best_outputs,'-o', lw=3, ms=20, label='from scratch')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yay! Looks like it works, although not very well. Explore and see what can be improved\n",
    "\n",
    "Acknowledgement: Content from this notebook is drawn from Ahmed Gad's GA implementation, found at his [Github](https://github.com/ahmedfgad/GeneticAlgorithmPython)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are not done yet!\n",
    "\n",
    "To have a black box optimizer, we need to wrap all this functionality into something that's abstracted away from the end user (in this case you). What does that mean? Think about:\n",
    "- Change in the cost function (Knapsack, Rastrigin)\n",
    "    - Function changes (and along with it discontinuities, ill-conditioning, non-separability...)\n",
    "    - Dimensionality of the problem changes (n=1,...,100,...1000?)\n",
    "    - Other concerns\n",
    "- Change in the encoding (reals, bitvectors)\n",
    "- ...\n",
    "\n",
    "That is to say, write something well once and keep on reusing it---functions! Also store associated variables---classes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW : Wrap this up in a GA class and reuse it in your applications (Project 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
