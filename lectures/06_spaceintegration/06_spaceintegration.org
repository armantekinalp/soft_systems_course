#+TITLE: Elastica : Spatial discretization
#+AUTHOR: /Tejaswin Parthasarathy/, Mattia Gazzola
#+SUBTITLE: ME498: Comp. modeling & optimization
#+BEAMER_FRAME_LEVEL: 2
# #+BEAMER_HEADER: \institute[INST]{Institute\\\url{http://www.institute.edu}}
# #+BEAMER_HEADER: \titlegraphic{\includegraphics[height=1.5cm]{test}}

#+STARTUP: beamer
#+LATEX_CLASS: beamer
#+LATEX_CLASS_OPTIONS: [presentation]
# #+LATEX_CLASS_OPTIONS: [notes]
#+LATEX_HEADER:\usetheme[progressbar=frametitle]{metropolis}
#+LATEX_HEADER:\usepackage{tikz}
#+LATEX_HEADER:\usetikzlibrary{intersections,calc}
#+LATEX_HEADER:\usepackage{pgfplots}
#+LATEX_HEADER:\pgfplotsset{compat=newest}
#+LATEX_HEADER:\usepackage{spot}
#+LATEX_HEADER:\newcommand{\gv}[1]{\ensuremath{\mbox{\boldmath$ #1 $}}}
#+LATEX_HEADER:\newcommand{\bv}[1]{\ensuremath{\mathbf{#1}}}
#+LATEX_HEADER:\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
#+LATEX_HEADER:\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
#+LATEX_HEADER:\newcommand{\bigqm}[1][1]{\text{\larger[#1]{\text{?}}}}
#+LATEX_HEADER:\newcommand{\order}[1]{\mathcal O \left( #1 \right)} % order of magnitude
#+LATEX_HEADER:\definecolor{scarlet}{rgb}{1.0, 0.13, 0.0}
#+LATEX_HEADER:\definecolor{shamrockgreen}{rgb}{0.0, 0.62, 0.38}
#+LATEX_HEADER:\definecolor{royalblue}{rgb}{0.25, 0.41, 0.88}
#+OPTIONS:   H:2 num:t toc:nil ::t |:t ^:{} -:t f:t *:t <:t
#+OPTIONS:   tex:t d:nil todo:t pri:nil tags:nil
#+COLUMNS: %45ITEM %10BEAMER_ENV(Env) %10BEAMER_ACT(Act) %4BEAMER_COL(Col) %8BEAMER_OPT(Opt)
* Introduction
** Integration and differentiation of functions
   More specifically numerical integration (*quadrature*) and differentiation
*** Integration                                                     :B_block:
	:PROPERTIES:
	:BEAMER_env: block
	:END:
	Given \( a, b, f \) compute a numerical approximation to
	\[ \int_{a}^{b} f(x) dx \]
	For purposes of this course, we assume \( f \) is Riemann integrable
      \Rightarrow Integral exists and is unique
*** Differentiation
	Given \( a, b, f \) compute a numerical approximation to
	\[ \frac{df}{dx} \; \in \; [a,b]\]
	Again we assume \( f \) is smooth enough (\( C^{r}\;\in\;[a,b]\))
** Where are these useful?
*** Everywhere!
	 - We /integrated/ quantitites in time in the last lecture (IVPs and
       timeseries analysis)
	 - Anything involving spatial quantities (BVPs, including solving PDEs using
       finite differences/volume/element, spectral element and so on...)
** Outline
   - More about quadrature, and what to look for in a quadrature rule
   - Simple (yet effective) quadrature schemes and their derivation
   - Do the same for numerical differentiation
   - Give context to these methods in our soft mechanics framework
* Quadrature
** Interpolatory quadrature
   - Design a quadrature method based on interpolation of values
   - *Why?* Typically values are known at few points in simulations
*** Linear combination
	- As integration is a linear operator, we perform a linear weighted
      combination of few function values
	\[ \int_{a}^{b} f(x) dx \approx \sum_{i=1}^{n} \omega_i f(x_i) \]
	- We can then play games with *nodes* (\(x_i\)) and *weights* (\(\omega_i\))
      \Rightarrow different quadrature rules
** What do we look for in a quadrature rule?
   While designing quadrature rules, you are concerned about
	- Accuracy (how correct is your answer, and whats the convergence)
	- Function evaluations
	- Stability (does your integral "blow up", in the presence of errors)?

	Choose \( x_i \) and \(\omega_i\) to minimize error \( \abs{\tilde{I} -I_h }
	\) while reducing number of function evaluations and robust to numerical errors
** TODO Midpoint and Trapezoidal rules
   #+CAPTION: Midpoint and trapezoidal rules
   #+ATTR_LATEX: :width 0.8\textwidth
   [[file:images/midpoint.jpg]]
*** Midpoint rule
	\[ I_h = (b-a) f \left( \frac{a + b}{2} \right) \]
*** Trapezoidal rule
	\[ I_h = \frac{(b-a)}{2} \left( f(a) + f(b) \right) \]
** Midpoint rule
   Suppose \( x \in [a,b] \) we have with Taylor series about \( c = \frac{a +
   b}{2} \)
   \[ \begin{aligned} f(x) &= f(c) + (x-c) f^\prime(c) +
   \frac{(x-c)^2}{2!}f^{\prime\prime}(c) + \cdots \end{aligned}\]
   Integrate this
   \[ \begin{aligned} I_{h} = \int_{a}^{b} f(x) dx &= hf(c) + \frac{(x-c)^2}{2} \biggr\rvert_{a}^{b} f^\prime(c) +
   \frac{(x-c)^3}{3!} \biggr\rvert_{a}^{b} f^{\prime\prime}(c) + \cdots \\
   & = (b-a) f \left( \frac{a + b}{2} \right) +
   \frac{h^3}{24}f^{\prime\prime}(c) + \frac{h^5}{1920}f^{iv}(c) + \cdots
   \end{aligned}\]
   Error is then:
   \[ e_h  = \frac{h^3}{24}f^{\prime\prime}(c) + \frac{h^5}{1920}f^{iv}(c) + \cdots\]
** Trapezoidal rule
   Suppose \( x \in [a,b] \) we have with Taylor series about \( c = \frac{a +
   b}{2} \)
   \[ \begin{aligned} f(a) &= f(c) - \frac{h}{2} f^\prime(c) +
   \frac{h^2}{2^2 \cdot 2!}f^{\prime\prime}(c) + \cdots \\
   f(b) &= f(c) + \frac{h}{2} f^\prime(c) +
   \frac{h^2}{2^2 \cdot 2!}f^{\prime\prime}(c) + \cdots \\
   \end{aligned}\]
   Adding and integrating (retaining the \(x\)-dependence),
   \[ \begin{aligned}
   \frac{(b-a)}{2} \left( f(a) + f(b) \right) &= I^{\text{midpoint}} +
   \frac{h^3}{2!2^2}f^{\prime\prime}(c) + \frac{h^5}{4!2^4}f^{iv}(c) + \cdots \\
   &= \tilde{I} +  \frac{h^3}{12}f^{\prime\prime}(c) + \frac{h^5}{480}f^{iv}(c) + \cdots \\
   \end{aligned}\]
   Error is then:
   \[ e_h  = \frac{h^3}{12}f^{\prime\prime}(c) + \frac{h^5}{480}f^{iv}(c) + \cdots\]
   *Twice* that of midpoint rule!
** Other quadrature rules
   - Many other better interpolatory (i.e. not only linear) quadrature rules exist...
   - If nodes are equispaced and interpolation is done using polynomials
     \Rightarrow *Newton--Cotes* quadrature (we discuss this)
   - If nodes are zeros of the Chebyshev polynomials and interpolation using
     same polynomials
     \Rightarrow *Clenshaw--Curtis* quadrature (seen in ~scipy.integrate.quad()~)
   - If nodes and weights are based on Legendre polynomials and Gauss--Legendre
     points \Rightarrow *Gaussian* quadrature
   - (Un)fortunately, we will not be discussing all of them in this course
** How do these perform?
   *DEMO*
   - Notice we have the \( 2x \) errors showing up in numerics as well
   - Does not work that well...Why?
   - The function to be integrated needs to be *linear* for perfect integration
     (even in the case of midpoint rule)
	 - Geometrical argument (from demo)
	 - Error estimates (highest derivative is 2, which vanishes for a linear function)
   - Of course, real functions are not---so what do we do?
   - *Composite rules*
** Composite rules in quadrature
   - Approximate function using many piecewise linears and sum up their
     contributions across all such approximations
	 - Mirrors definition of Riemann integrable functions
	 - More work per integration (many more function evaluations)
	 - But...better estimates!
   - How good is our approximation? Seek error estimates...
   #+begin_export latex
   \begin{center}
   \begin{tikzpicture}[scale=0.5]
   \coordinate (p1) at (0.7,3);
   \coordinate (p2) at (1,3.3);
   \coordinate (p3) at (2,2.5);
   \coordinate (p4) at (3,2.5);
   \coordinate (p5) at (4,3.5);
   \coordinate (p6) at (5,4.1);
   \coordinate (p7) at (6,3.4);
   \coordinate (p8) at (7,4.1);
   \coordinate (p9) at (8,4.6);
   \coordinate (p10) at (9,4);
   \coordinate (p11) at (9.5,4.7);

   % The cyan background
   \fill[royalblue!10]
   (p2|-0,0) -- (p2) -- (p3) -- (p4) -- (p5) -- (p6) -- (p7) -- (p8) -- (p9) -- (p10) -- (p10|-0,0) -- cycle;
   % the dark cyan stripe
   \fill[royalblue!30] (p6|-0,0) -- (p6) -- (p7) -- (p7|-0,0) -- cycle;
   % the curve
   \draw[thick,royalblue]
   (p1) to[out=70,in=180] (p2) to[out=0,in=150]
   (p3) to[out=-50,in=230] (p4) to[out=30,in=220]
   (p5) to[out=50,in=150] (p6) to[out=-30,in=180]
   (p7) to[out=0,in=230] (p8) to[out=40,in=180]
   (p9) to[out=-30,in=180] (p10) to[out=0,in=260] (p11);
   % the broken line connecting points on the curve
   \draw (p2) -- (p3) -- (p4) -- (p5) -- (p6) -- (p7) -- (p8) -- (p9) -- (p10);
   % vertical lines and labels
   \foreach \n/\texto in {2/{x_0},3/{x_1},4/{},5/{},6/{x_{j-1}},7/{x_j},8/{},9/{x_{n-1}},10/{x_n}}
   {
   \draw (p\n|-0,0) -- (p\n);
   \node[below,text height=1.5ex,text depth=1ex,font=\small] at (p\n|-0,0) {$\texto$};
   }
   % The axes
   \draw[->] (-0.5,0) -- (10,0) coordinate (x axis);
   \draw[->] (0,-0.5) -- (0,6) coordinate (y axis);
   % labels for the axes
   \node[below] at (x axis) {$x$};
   \node[left] at (y axis) {$y$};
   % label for the function
   \node[above,text=royalblue] at (p11) {$y=f(x)$};
   \end{tikzpicture}
   \end{center}
   #+end_export
** Composition using Trapezoidal rule
   \[ \begin{aligned} I_{\text{CT}} &= h \left[ \sum_{i=1}^{n-1} f_i +
   \frac{1}{2}(f_0 + f_n) \right] \\
   &= \sum_{i=1}^{n}\frac{h}{2} \left[ f_{i-1} + f_{i}\right] \\
   &= \sum_{i=1}^{n} \left[ \tilde{I} +  c_2{h^3}f^{\prime\prime}(x_{i-\frac{1}{2}}) + c_4{h^5}f^{iv}(x_{i-\frac{1}{2}}) +
   c_6{h^7}f^{vi}(x_{i-\frac{1}{2}}) + \cdots \right] \\
   &= \tilde{I} + c_2h^2 \left[ h \sum_{i=1}^{n}
   f^{\prime\prime}(x_{i-\frac{1}{2}})\right] +  c_4h^4 \left[ h \sum_{i=1}^{n}
   f^{iv}(x_{i-\frac{1}{2}}) \right] + \cdots \\
   &= \tilde{I} + \frac{h^2}{12} \left[ \int_{a}^{b} f^{\prime\prime}dx +
   \text{h.o.t} + \right]  + \frac{h^4}{480} \left[ \int_{a}^{b} f^{iv}dx +
   \text{h.o.t} + \right] + \cdots \\
   &= \tilde{I} + \frac{h^2}{12} \left[ f^\prime(b) - f^\prime(a) \right] + h.o.t.
   \end{aligned}\]
** Composite rules in quadrature
   - *Observation* We lose an order of accuracy in cumulation!
   - Is this seen numerically? *DEMO*
   - Even in timestepping, this is observed (*Local* truncation error vs
     *Global* truncation error)
   - But, we get good estimates of the integral (especially for polynomials)
** Integrand dependence
   - Does it depend on the function being integrated?
   - *DEMO*
   - *Yes*. Depending upon the end point conditions:
	 - Standard case (nothing special happens)
	 - Lucky (\(f^\prime(a) = f^\prime(b) = 0 \))
	 - More lucky (\(f^{(k)}(a) = f^{(k)}(b) = 0 \;, k = 1,2,\cdots \))
	 - Unlucky (\(f^{\prime}(a) = \infty \))
   we may get better/worse performance...
** Stability of quadrature
   - We won't explicitly dicuss stability
   - *Rule of thumb*---no negative weights in interpolatory quadrature
   - All discussed quadrature rules are stable
** Soft mechanics framework
   Many temporal and spatial integrations. More explicitly,

   \[ \spot<2>{\begin{aligned}
   \frac{\partial \bv{d}_j}{\partial t} &= \left( \bv{Q}^T
   \omega_{\mathcal{L}}\right) \times \bv{d}_j \\
   \frac{\partial \bv{d}_j}{\partial s} &= \left( \bv{Q}^T
   \kappa_{\mathcal{L}}\right) \times \bv{d}_j
   \end{aligned}} \]
*** Analytical integration using exponentials                       :B_block:
	:PROPERTIES:
	:BEAMER_ACT: <2->
	:BEAMER_env: block
	:END:
***                                                         :B_ignoreheading:
	:PROPERTIES:
	:BEAMER_env: ignoreheading
	:END:
	\[ \spot<3>{\begin{aligned}\frac{\hat{\mathbf{J}}_i}{e_i} \cdot \frac{\partial
	\boldsymbol{\omega}^i_{\mathcal{L}}}{\partial t} &=
	\Delta^h\left(\frac{\hat{\boldsymbol{\mathcal{B}}}_i\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^{i}}{\mathcal{E}_i^3}\right) +
	\mathcal{A}^h\left(\frac{\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i\times\hat{\boldsymbol{\mathcal{B}}}_i
	\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i}{\mathcal{E}_i^3}
	\hat{\mathcal{D}}_i\right) + \left(\mathbf{Q}_i\mathbf{t}_i\times\hat{\mathbf{S}}_i\boldsymbol{\sigma}^i_{\mathcal{L}}\right)\hat{\ell}_i\\
	&+ \mathbf{C}^i_{\mathcal{L}},\quad i=[1,n] \end{aligned}}\]

   # \[\begin{aligned} \frac{\hat{\mathbf{J}}_i}{e_i} \cdot \frac{\partial
   # \boldsymbol{\omega}^i_{\mathcal{L}}}{\partial t} &=
   # \Delta^h\left(\frac{\hat{\boldsymbol{\mathcal{B}}}_i\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^{i}}{\mathcal{E}_i^3}\right) +
   # \mathcal{A}^h\left(\frac{\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i\times\hat{\boldsymbol{\mathcal{B}}}_i
   # \hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i}{\mathcal{E}_i^3}
   # \hat{\mathcal{D}}_i\right) + \left(\mathbf{Q}_i\mathbf{t}_i\times\hat{\mathbf{S}}_i\boldsymbol{\sigma}^i_{\mathcal{L}}\right)\hat{\ell}_i\\
   # &+\left(\hat{\mathbf{J}}_i\cdot\frac{\boldsymbol{\omega}^i_{\mathcal{L}}}{e_i}\right)\times
   # \boldsymbol{\omega}^i_{\mathcal{L}} +
   # \frac{\hat{\mathbf{J}}_i\boldsymbol{\omega}^i_{\mathcal{L}}}{e_i^2}\cdot\frac{\partial
   # e_i}{\partial t}
   # + \mathbf{C}^i_{\mathcal{L}},\hspace{2.5cm}i=[1,n]
   # \end{aligned} \]
*** \(\mathcal{A}^{h} \) using trapezoidal quadrature                   :B_block:
	:PROPERTIES:
	:BEAMER_env: block
	:BEAMER_ACT: <3->
	:END:
* Differentiation
** Derivatives
   - Frequently we need to take derivatives of functions (sampled at
     unique points)
   - One simple yet effective approach is using *finite-difference* formulae
*** Linear combination
	- As differentiation (wrt to one independent variable) is a linear operator,
      we once again perform a linear weighted combination of few function values
	  \[ \frac{d f(x)}{d x} \approx \sum_{i=1}^{n} \omega_i f(x_i) \]
	- We can then play games with *nodes* (\(x_i\)) and *weights* (\(\omega_i\))
      \Rightarrow different finite difference formulae
** Example
   An example illustrating the simplest FD formula (recall the timestepping lecture)
*** First principles                                              :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:

	\[ f^{\prime}(x) = \lim_{h \to 0} \frac{f(x+h) - f(x) }{h}\]
	Finite differences stop before the limit is reached (i.e. they have finite
	\( h \) )
** Considerations for differentiation schemes?
   While designing differentiation schemes, you are concerned about
	 - Cost (i.e. function evaluations)
	 - Accuracy (truncation error, how convergent is your scheme)
	 - Round-off errors
	 - Both these relate to stability too...

   These issues are sometimes subtle (because of the nature of differentiation),
   and so we need to be careful...
** Schemes for first-order derivatives
   Using Taylor series expansion, you can obtain arbitrary-order derivatives
   with arbitrary-order convergence. Some examples to approximate \(
   \frac{df(x)}{dx}\) are shown below ( \(\delta\) represents discrete
   differences)
*** Forward differences                                           :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta f(x)}{\delta x} = \frac{f(x+h) - f(x)}{h}\]
*** Backward differences                                          :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta f(x)}{\delta x} = \frac{f(x) - f(x-h)}{h}\]
*** Centered differences                                          :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta f(x)}{\delta x} = \frac{f(x+h) - f(x-h)}{2h}\]

** Schemes for higher-order derivatives
   Examples for second order derivatives
*** Forward differences                                           :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta^2 f(x)}{\delta x^2} = \frac{f(x)-2f(x+h)+f(x+2h)}{1h^{2}} \]
*** Backward differences                                          :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta^2 f(x)}{\delta x^2} = \frac{f(x)-2f(x-h)+f(x-2h)}{1h^{2}} \]
*** Centered differences                                          :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta^2 f(x)}{\delta x^2} = \frac{f(x+h)-2f(x)+f(x-h)}{1h^{2}} \]
** What do these do?
*** More schemes                                                    :B_block:
	:PROPERTIES:
	:BEAMER_env: block
	:END:
	Take a look at [[http://web.media.mit.edu/~crtaylor/calculator.html][MIT Finite Difference Calculator]] (sympy also has this
	capability) and build your own schemes!
*** Local polynomial representations                                :B_block:
	:PROPERTIES:
	:BEAMER_env: block
	:BEAMER_COL: 0.6
	:END:
	Finite differences assume your function is locally a polynomial (order
	depending upon the order of the finite difference calculation) and takes
	derivatives of these polynomials...
***                                                                :B_column:
	:PROPERTIES:
	:BEAMER_env: column
	:BEAMER_COL: 0.5
	:END:
   #+CAPTION: First derivative approximation
   #+ATTR_LATEX: :width 1.0\textwidth
	[[file:images/fdiff.jpg]]

** How do these perform (accuracy) ?
   *DEMO* using calculation of \( \frac{df}{dx} \)
   - Order of accuracy depends upon the Taylor series representation (*Taylor
     theorem*)
   - For the same function evaluations i.e. if \( n \) is the number of points
     considered in our algorithm
	 - Quadrature is accurate to \( \order{h^{n+1}}\)
	 - Differentation is accurate to \( \order{h^{n-1}}\)
   - Centered difference algorithms usually have a bump in order of accuracy,
     for the same width of stencil
   - Lots of freedom to design own schemes...
** Round-off errors
*** Why discuss round-off errors?
	 - Round-off errors : errors in precisely representing numbers on a computer
	 - Finite precision effects where not important in quadrature, but are so in
       differentation.
	 - *Why*? Numerical differentation is susceptible to:
	   - Noise amplification
	   - Cancellation errors (due to signs)
	   - And as we saw last slide, is less accurate than quadrature
*** Effect of round-off
	- If \( \epsilon \) is machine precision \( 2^{-52} \approx 10^{-16} \) in
      double precision we can show
	\[\frac{\delta f(x)}{\delta x} = \frac{f(x+h) - f(x)}{h} \approx
	f^{\prime}(x)  + \frac{h}{2}f^{\prime\prime}(x) + \frac{\epsilon \cdot
	f}{h} + \order{h^2} \]
** Caution!!!
   In an ideal world, we should not be taking derivatives of functions
   numerically:
   - Differentation is /unbounded/:
	 A function with small \( \norm{f}_{\infty} \) can have arbitrarily large \(
     \norm{f^{\prime}}_{\infty} \) *DEMO*
   - Differentiation amplifies noise:
	 Smooth function with small, high-frequency wiggles (common in experiments
     and under-resolved simulations) can explode *DEMO*
   - Numerical differentiation : subject to cancellation and round-off errors *DEMO*
** Soft mechanics framework
   Many spatial differentiations. More explicitly,

   \[ \spot<2>{\begin{aligned}
   m_i \cdot \frac{\partial \mathbf{v}_i}{\partial t} &= \Delta^h
   \left(\frac{\mathbf{Q}_i^T\hat{\mathbf{S}}_i\boldsymbol{\sigma}^i_{\mathcal{L}}}{e_i}\right)
   +\mathbf{F}_i,\quad i=[1,n+1]
   \end{aligned}} \]
***                                                         :B_ignoreheading:
	:PROPERTIES:
	:BEAMER_env: ignoreheading
	:END:
	\[ \spot<3>{\begin{aligned}\frac{\hat{\mathbf{J}}_i}{e_i} \cdot \frac{\partial
	\boldsymbol{\omega}^i_{\mathcal{L}}}{\partial t} &=
	\Delta^h\left(\frac{\hat{\boldsymbol{\mathcal{B}}}_i\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^{i}}{\mathcal{E}_i^3}\right) +
	\mathcal{A}^h\left(\frac{\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i\times\hat{\boldsymbol{\mathcal{B}}}_i
	\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i}{\mathcal{E}_i^3}
	\hat{\mathcal{D}}_i\right) + \left(\mathbf{Q}_i\mathbf{t}_i\times\hat{\mathbf{S}}_i\boldsymbol{\sigma}^i_{\mathcal{L}}\right)\hat{\ell}_i\\
	&+ \mathbf{C}^i_{\mathcal{L}},\quad i=[1,n] \end{aligned}}\]

   # \[\begin{aligned} \frac{\hat{\mathbf{J}}_i}{e_i} \cdot \frac{\partial
   # \boldsymbol{\omega}^i_{\mathcal{L}}}{\partial t} &=
   # \Delta^h\left(\frac{\hat{\boldsymbol{\mathcal{B}}}_i\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^{i}}{\mathcal{E}_i^3}\right) +
   # \mathcal{A}^h\left(\frac{\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i\times\hat{\boldsymbol{\mathcal{B}}}_i
   # \hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i}{\mathcal{E}_i^3}
   # \hat{\mathcal{D}}_i\right) + \left(\mathbf{Q}_i\mathbf{t}_i\times\hat{\mathbf{S}}_i\boldsymbol{\sigma}^i_{\mathcal{L}}\right)\hat{\ell}_i\\
   # &+\left(\hat{\mathbf{J}}_i\cdot\frac{\boldsymbol{\omega}^i_{\mathcal{L}}}{e_i}\right)\times
   # \boldsymbol{\omega}^i_{\mathcal{L}} +
   # \frac{\hat{\mathbf{J}}_i\boldsymbol{\omega}^i_{\mathcal{L}}}{e_i^2}\cdot\frac{\partial
   # e_i}{\partial t}
   # + \mathbf{C}^i_{\mathcal{L}},\hspace{2.5cm}i=[1,n]
   # \end{aligned} \]
*** \(\Delta^{h} \) using finite differences                        :B_block:
	:PROPERTIES:
	:BEAMER_env: block
	:BEAMER_ACT: <3->
	:END:
