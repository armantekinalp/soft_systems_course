#+TITLE: Elastica : Spatial discretization
#+AUTHOR: /Tejaswin Parthasarathy/, Mattia Gazzola
#+SUBTITLE: ME498: Comp. modeling & optimization
#+BEAMER_FRAME_LEVEL: 2
# #+BEAMER_HEADER: \institute[INST]{Institute\\\url{http://www.institute.edu}}
# #+BEAMER_HEADER: \titlegraphic{\includegraphics[height=1.5cm]{test}}

#+STARTUP: beamer
#+LATEX_CLASS: beamer
#+LATEX_CLASS_OPTIONS: [presentation]
# #+LATEX_CLASS_OPTIONS: [notes]
#+LATEX_HEADER:\usetheme[progressbar=frametitle]{metropolis}
#+LATEX_HEADER:\usepackage{tikz}
#+LATEX_HEADER:\usepackage{tikz-3dplot}
#+LATEX_HEADER:\usetikzlibrary{intersections,calc,shapes.geometric}
#+LATEX_HEADER:\usepackage{pgfplots}
#+LATEX_HEADER:\pgfplotsset{compat=newest}
#+LATEX_HEADER:\usepackage{spot}
#+LATEX_HEADER:\newcommand{\gv}[1]{\ensuremath{\mbox{\boldmath$ #1 $}}}
#+LATEX_HEADER:\newcommand{\bv}[1]{\ensuremath{\mathbf{#1}}}
#+LATEX_HEADER:\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
#+LATEX_HEADER:\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
#+LATEX_HEADER:\newcommand{\bigqm}[1][1]{\text{\larger[#1]{\text{?}}}}
#+LATEX_HEADER:\newcommand{\order}[1]{\mathcal O \left( #1 \right)} % order of magnitude
#+LATEX_HEADER:\definecolor{scarlet}{rgb}{1.0, 0.13, 0.0}
#+LATEX_HEADER:\definecolor{shamrockgreen}{rgb}{0.0, 0.62, 0.38}
#+LATEX_HEADER:\definecolor{royalblue}{rgb}{0.25, 0.41, 0.88}
#+LATEX_HEADER:\definecolor{metropolisorange}{RGB}{235,129,27}
#+LATEX_HEADER:\definecolor{metropolisblue}{RGB}{35,55,59}
#+OPTIONS:   H:2 num:t toc:nil ::t |:t ^:{} -:t f:t *:t <:t
#+OPTIONS:   tex:t d:nil todo:t pri:nil tags:nil
#+COLUMNS: %45ITEM %10BEAMER_ENV(Env) %10BEAMER_ACT(Act) %4BEAMER_COL(Col) %8BEAMER_OPT(Opt)

#+begin_export latex
\tikzset{>=latex}
#+end_export
* Introduction
** Integration and differentiation of functions
   More specifically numerical integration (*quadrature*) and differentiation
*** Integration                                                     :B_block:
	:PROPERTIES:
	:BEAMER_env: block
	:END:
	Given \( a, b, f \) compute a numerical approximation to
	\[ \int_{a}^{b} f(x) dx \]
	For purposes of this course, we assume \( f \) is Riemann integrable
      \Rightarrow Integral exists and is unique
*** Differentiation
	Given \( a, b, f \) compute a numerical approximation to
	\[ \frac{df}{dx} \; \in \; [a,b]\]
	Again we assume \( f \) is smooth enough (\( C^{r}\;\in\;[a,b]\))
** Where are these useful?
*** Everywhere!
	 - We /integrated/ quantitites in time in the last lecture (IVPs and
       timeseries analysis)
	 - Anything involving spatial quantities (BVPs, including solving PDEs using
       finite differences/volume/element, spectral element and so on...)
** Outline
   - More about quadrature, and what to look for in a quadrature rule
   - Simple (yet effective) quadrature schemes and their derivation
   - Do the same for numerical differentiation
   - Give context to these methods in our soft mechanics framework
* Quadrature
** Interpolatory quadrature
   - Design a quadrature method based on interpolation of values
   - *Why?* Typically values are known at few points in simulations
*** Linear combination
	- As integration is a linear operator, we perform a linear weighted
      combination of few function values
	\[ \int_{a}^{b} f(x) dx \approx \sum_{i=1}^{n} \omega_i f(x_i) \]
	- We can then play games with *nodes* (\(x_i\)) and *weights* (\(\omega_i\))
      \Rightarrow different quadrature rules
** What do we look for in a quadrature rule?
   While designing quadrature rules, you are concerned about
	- Accuracy (how correct is your answer, and whats the convergence)
	- Function evaluations
	- Stability (does your integral "blow up", in the presence of errors)?

	Choose \( x_i \) and \(\omega_i\) to minimize error \( \abs{\tilde{I} -I_h }
	\) while reducing number of function evaluations and robust to numerical errors
** Midpoint and Trapezoidal rules
   #+CAPTION: Midpoint and trapezoidal rules
   # #+ATTR_LATEX: :width 0.8\textwidth
   # [[file:images/midpoint.jpg]]
***                                                                :B_column:
	:PROPERTIES:
	:BEAMER_env: column
	:BEAMER_COL: 0.5
	:END:
	 #+begin_export latex
	 \begin{center}
		 \begin{tikzpicture}[
		 declare function={func(\x)=sin(deg(pi*\x));},
		 declare function={funcder(\x)=pi*cos(deg(pi*\x));}]
		 \begin{axis}%
			 [grid=none,
			 axis x line=bottom,
			 axis y line=left,
			 domain=1.52:1.62,
			 xmin=1.50,
			 xmax=1.64,
			 ymax=-0.92,
			 ymin=-1.02,
			 xlabel={$t$},
			 ylabel={$u(t)$},
			 ticks=none,
			 width=1.1\textwidth,
			 title={Midpoint rule},
			 title style={at={(0.5,1.0)},anchor=north},
			 enlargelimits=false,
			 ]
			 \addplot[smooth, very thick,
			 color=metropolisorange]{func(x)};

			 % Add rectangle betewen 1.53 and 1.61
			 \filldraw[thick, color=metropolisblue, fill=metropolisblue, fill opacity=0.2]
			 (axis cs: 1.53, \pgfkeysvalueof{/pgfplots/ymin})
			 rectangle (axis cs: 1.61,{func(1.57)});

			 % Draw point
			 \node (M) [circle, minimum size=5, inner sep=0, fill=metropolisorange]
			 at (axis cs: 1.57, {func(1.57)}) {};

		 \end{axis}
		 \end{tikzpicture}
	 \end{center}
	 #+end_export

***                                                                :B_column:
	:PROPERTIES:
	:BEAMER_env: column
	:BEAMER_COL: 0.5
	:END:
	 #+begin_export latex
	 \begin{center}
		 \begin{tikzpicture}[
		 declare function={func(\x)=sin(deg(pi*\x));},
		 declare function={funcder(\x)=pi*cos(deg(pi*\x));}]
		 \begin{axis}%
			 [grid=none,
			 axis x line=bottom,
			 axis y line=left,
			 domain=1.52:1.62,
			 xmin=1.50,
			 xmax=1.64,
			 ymax=-0.92,
			 ymin=-1.02,
			 xlabel={$t$},
			 ylabel={$u(t)$},
			 ticks=none,
			 width=1.1\textwidth,
			 title={Trapezoidal rule},
			 title style={at={(0.5,1.0)},anchor=north},
			 enlargelimits=false,
			 disabledatascaling
			 ]
			 \addplot[smooth, very thick,
			 color=metropolisorange]{func(x)};

			 % Draw point
			 \node (M) [circle, minimum size=5, inner sep=0, fill=metropolisorange]
			 at (axis cs: 1.57, {func(1.57)}) {};

			 % Add trapezoid betewen 1.53 and 1.61 by first defining coordinates
			 % https://tex.stackexchange.com/a/324328
			 \path (M) + (axis cs:-0.04,{-funcder(1.57)*0.04}) coordinate (A);
			 \path (A) + (axis cs:0.0,\pgfkeysvalueof{/pgfplots/ymin}) coordinate (Ad);
			 \path (M) + (axis cs:0.04, {funcder(1.57)*0.04}) coordinate (B);
			 \path (B) + (axis cs:0.0,\pgfkeysvalueof{/pgfplots/ymin}) coordinate (Bd);

			 \draw [thick, color=metropolisblue, fill=metropolisblue, fill opacity=0.2]
			 (M) -- (A) -- (Ad) -- (Bd) -- (B) -- cycle;

			 % Add rectangle betewen 1.53 and 1.61
			 \draw[dashed, thin]
			 (axis cs: 1.53, \pgfkeysvalueof{/pgfplots/ymin})
			 rectangle (axis cs: 1.61,{func(1.57)});

		 \end{axis}
		 \end{tikzpicture}
	 \end{center}
	 #+end_export

*** Midpoint rule
	\[ I_h = (b-a) f \left( \frac{a + b}{2} \right) \]
*** Trapezoidal rule
	\[ I_h = \frac{(b-a)}{2} \left( f(a) + f(b) \right) \]
** Midpoint rule
   Suppose \( x \in [a,b] \) we have with Taylor series about \( c = \frac{a +
   b}{2} \)
   \[ \begin{aligned} f(x) &= f(c) + (x-c) f^\prime(c) +
   \frac{(x-c)^2}{2!}f^{\prime\prime}(c) + \cdots \end{aligned}\]
   Integrate this
   \[ \begin{aligned} I_{h} = \int_{a}^{b} f(x) dx &= hf(c) + \frac{(x-c)^2}{2} \biggr\rvert_{a}^{b} f^\prime(c) +
   \frac{(x-c)^3}{3!} \biggr\rvert_{a}^{b} f^{\prime\prime}(c) + \cdots \\
   & = (b-a) f \left( \frac{a + b}{2} \right) +
   \frac{h^3}{24}f^{\prime\prime}(c) + \frac{h^5}{1920}f^{iv}(c) + \cdots
   \end{aligned}\]
   Error is then:
   \[ e_h  = \frac{h^3}{24}f^{\prime\prime}(c) + \frac{h^5}{1920}f^{iv}(c) + \cdots\]
** Trapezoidal rule
   Suppose \( x \in [a,b] \) we have with Taylor series about \( c = \frac{a +
   b}{2} \)
   \[ \begin{aligned} f(a) &= f(c) - \frac{h}{2} f^\prime(c) +
   \frac{h^2}{2^2 \cdot 2!}f^{\prime\prime}(c) + \cdots \\
   f(b) &= f(c) + \frac{h}{2} f^\prime(c) +
   \frac{h^2}{2^2 \cdot 2!}f^{\prime\prime}(c) + \cdots \\
   \end{aligned}\]
   Adding and integrating (retaining the \(x\)-dependence),
   \[ \begin{aligned}
   \frac{(b-a)}{2} \left( f(a) + f(b) \right) &= I^{\text{midpoint}} +
   \frac{h^3}{2!2^2}f^{\prime\prime}(c) + \frac{h^5}{4!2^4}f^{iv}(c) + \cdots \\
   &= \tilde{I} +  \frac{h^3}{12}f^{\prime\prime}(c) + \frac{h^5}{480}f^{iv}(c) + \cdots \\
   \end{aligned}\]
   Error is then:
   \[ e_h  = \frac{h^3}{12}f^{\prime\prime}(c) + \frac{h^5}{480}f^{iv}(c) + \cdots\]
   *Twice* that of midpoint rule!
** Other quadrature rules
   - Many other better interpolatory (i.e. not only linear) quadrature rules exist...
   - If nodes are equispaced and interpolation is done using polynomials
     \Rightarrow *Newton--Cotes* quadrature (we discuss this)
   - If nodes are zeros of the Chebyshev polynomials and interpolation using
     same polynomials
     \Rightarrow *Clenshaw--Curtis* quadrature (seen in ~scipy.integrate.quad()~)
   - If nodes and weights are based on Legendre polynomials and Gauss--Legendre
     points \Rightarrow *Gaussian* quadrature
   - (Un)fortunately, we will not be discussing all of them in this course
** How do these perform?
   *DEMO*
   - Notice we have the \( 2x \) errors showing up in numerics as well
   - Does not work that well...Why?
   - The function to be integrated needs to be *linear* for perfect integration
     (even in the case of midpoint rule)
	 - Geometrical argument (from demo)
	 - Error estimates (highest derivative is 2, which vanishes for a linear function)
   - Of course, real functions are not---so what do we do?
   - *Composite rules*
** Composite rules in quadrature
   - Approximate function using many piecewise linears and sum up their
     contributions across all such approximations
	 - Mirrors definition of Riemann integrable functions
	 - More work per integration (many more function evaluations)
	 - But...better estimates!
   - How good is our approximation? Seek error estimates...
   #+begin_export latex
   \begin{center}
   \begin{tikzpicture}[scale=0.5]
   \coordinate (p1) at (0.7,3);
   \coordinate (p2) at (1,3.3);
   \coordinate (p3) at (2,2.5);
   \coordinate (p4) at (3,2.5);
   \coordinate (p5) at (4,3.5);
   \coordinate (p6) at (5,4.1);
   \coordinate (p7) at (6,3.4);
   \coordinate (p8) at (7,4.1);
   \coordinate (p9) at (8,4.6);
   \coordinate (p10) at (9,4);
   \coordinate (p11) at (9.5,4.7);

   % The cyan background
   \fill[metropolisblue, fill opacity = 0.2]
   (p2|-0,0) -- (p2) -- (p3) -- (p4) -- (p5) -- (p6) -- (p7) -- (p8) -- (p9) -- (p10) -- (p10|-0,0) -- cycle;
   % the dark cyan stripe
   \fill[metropolisblue, fill opacity = 0.6] (p6|-0,0) -- (p6) -- (p7) -- (p7|-0,0) -- cycle;
   % the curve
   \draw[thick,metropolisorange]
   (p1) to[out=70,in=180] (p2) to[out=0,in=150]
   (p3) to[out=-50,in=230] (p4) to[out=30,in=220]
   (p5) to[out=50,in=150] (p6) to[out=-30,in=180]
   (p7) to[out=0,in=230] (p8) to[out=40,in=180]
   (p9) to[out=-30,in=180] (p10) to[out=0,in=260] (p11);
   % the broken line connecting points on the curve
   \draw (p2) -- (p3) -- (p4) -- (p5) -- (p6) -- (p7) -- (p8) -- (p9) -- (p10);
   % vertical lines and labels
   \foreach \n/\texto in {2/{x_0},3/{x_1},4/{},5/{},6/{x_{j-1}},7/{x_j},8/{},9/{x_{n-1}},10/{x_n}}
   {
   \draw (p\n|-0,0) -- (p\n);
   \node[below,text height=1.5ex,text depth=1ex,font=\small] at (p\n|-0,0) {$\texto$};
   }
   % The axes
   \draw[->] (-0.5,0) -- (10,0) coordinate (x axis);
   \draw[->] (0,-0.5) -- (0,6) coordinate (y axis);
   % labels for the axes
   \node[below] at (x axis) {$x$};
   \node[left] at (y axis) {$y$};
   % label for the function
   \node[above,text=metropolisorange] at (p11) {$y=f(x)$};
   \end{tikzpicture}
   \end{center}
   #+end_export
** Composition using Trapezoidal rule
   \[ \begin{aligned} I_{\text{CT}} &= h \left[ \sum_{i=1}^{n-1} f_i +
   \frac{1}{2}(f_0 + f_n) \right] \\
   &= \sum_{i=1}^{n}\frac{h}{2} \left[ f_{i-1} + f_{i}\right] \\
   &= \sum_{i=1}^{n} \left[ \tilde{I} +  c_2{h^3}f^{\prime\prime}(x_{i-\frac{1}{2}}) + c_4{h^5}f^{iv}(x_{i-\frac{1}{2}}) +
   c_6{h^7}f^{vi}(x_{i-\frac{1}{2}}) + \cdots \right] \\
   &= \tilde{I} + c_2h^2 \left[ h \sum_{i=1}^{n}
   f^{\prime\prime}(x_{i-\frac{1}{2}})\right] +  c_4h^4 \left[ h \sum_{i=1}^{n}
   f^{iv}(x_{i-\frac{1}{2}}) \right] + \cdots \\
   &= \tilde{I} + \frac{h^2}{12} \left[ \int_{a}^{b} f^{\prime\prime}dx +
   \text{h.o.t} + \right]  + \frac{h^4}{480} \left[ \int_{a}^{b} f^{iv}dx +
   \text{h.o.t} + \right] + \cdots \\
   &= \tilde{I} + \frac{h^2}{12} \left[ f^\prime(b) - f^\prime(a) \right] + h.o.t.
   \end{aligned}\]
** Composite rules in quadrature
   - *Observation* We lose an order of accuracy in cumulation!
   - Is this seen numerically? *DEMO*
   - Even in timestepping, this is observed (*Local* truncation error vs
     *Global* truncation error)
   - But, we get good estimates of the integral (especially for polynomials)
** Integrand dependence
   - Does it depend on the function being integrated?
   - *DEMO*
   - *Yes*. Depending upon the end point conditions:
	 - Standard case (nothing special happens)
	 - Lucky (\(f^\prime(a) = f^\prime(b) = 0 \))
	 - More lucky (\(f^{(k)}(a) = f^{(k)}(b) = 0 \;, k = 1,2,\cdots \))
	 - Unlucky (\(f^{\prime}(a) = \infty \))
   we may get better/worse performance...
** Stability of quadrature
   - We won't explicitly dicuss stability
   - *Rule of thumb*---no negative weights in interpolatory quadrature
   - All discussed quadrature rules are stable
** Soft mechanics framework
   Many temporal and spatial integrations. More explicitly,

   \[ \spot<2>{\begin{aligned}
   \frac{\partial \bv{d}_j}{\partial t} &= \left( \bv{Q}^T
   \omega_{\mathcal{L}}\right) \times \bv{d}_j \\
   \frac{\partial \bv{d}_j}{\partial s} &= \left( \bv{Q}^T
   \kappa_{\mathcal{L}}\right) \times \bv{d}_j
   \end{aligned}} \]
*** Analytical integration using exponentials                       :B_block:
	:PROPERTIES:
	:BEAMER_ACT: <2->
	:BEAMER_env: block
	:END:
***                                                         :B_ignoreheading:
	:PROPERTIES:
	:BEAMER_env: ignoreheading
	:END:
	\[ \spot<3>{\begin{aligned}\frac{\hat{\mathbf{J}}_i}{e_i} \cdot \frac{\partial
	\boldsymbol{\omega}^i_{\mathcal{L}}}{\partial t} &=
	\Delta^h\left(\frac{\hat{\boldsymbol{\mathcal{B}}}_i\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^{i}}{\mathcal{E}_i^3}\right) +
	\mathcal{A}^h\left(\frac{\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i\times\hat{\boldsymbol{\mathcal{B}}}_i
	\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i}{\mathcal{E}_i^3}
	\hat{\mathcal{D}}_i\right) + \left(\mathbf{Q}_i\mathbf{t}_i\times\hat{\mathbf{S}}_i\boldsymbol{\sigma}^i_{\mathcal{L}}\right)\hat{\ell}_i\\
	&+ \mathbf{C}^i_{\mathcal{L}},\quad i=[1,n] \end{aligned}}\]

   # \[\begin{aligned} \frac{\hat{\mathbf{J}}_i}{e_i} \cdot \frac{\partial
   # \boldsymbol{\omega}^i_{\mathcal{L}}}{\partial t} &=
   # \Delta^h\left(\frac{\hat{\boldsymbol{\mathcal{B}}}_i\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^{i}}{\mathcal{E}_i^3}\right) +
   # \mathcal{A}^h\left(\frac{\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i\times\hat{\boldsymbol{\mathcal{B}}}_i
   # \hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i}{\mathcal{E}_i^3}
   # \hat{\mathcal{D}}_i\right) + \left(\mathbf{Q}_i\mathbf{t}_i\times\hat{\mathbf{S}}_i\boldsymbol{\sigma}^i_{\mathcal{L}}\right)\hat{\ell}_i\\
   # &+\left(\hat{\mathbf{J}}_i\cdot\frac{\boldsymbol{\omega}^i_{\mathcal{L}}}{e_i}\right)\times
   # \boldsymbol{\omega}^i_{\mathcal{L}} +
   # \frac{\hat{\mathbf{J}}_i\boldsymbol{\omega}^i_{\mathcal{L}}}{e_i^2}\cdot\frac{\partial
   # e_i}{\partial t}
   # + \mathbf{C}^i_{\mathcal{L}},\hspace{2.5cm}i=[1,n]
   # \end{aligned} \]
*** \(\mathcal{A}^{h} \) using trapezoidal quadrature                   :B_block:
	:PROPERTIES:
	:BEAMER_env: block
	:BEAMER_ACT: <3->
	:END:
** The \( \mathcal{A}^{h} \) operator
   Define the \( \mathcal{A}^{h} \) operator as:
   \[ \mathbf{y}_{j=1, \ldots, N+1}=\mathcal{A}^{h}\left(\mathbf{x}_{i=1, \ldots
   N}\right)=\left\{\begin{array}{ll}{\frac{\mathbf{x}_{1}}{2}} & {\text { if }
   j=1} \\ {\frac{\mathbf{x}_{j}+\mathbf{x}_{j-1}}{2}} & {\text { if } 1<j \leq
   N} \\ {\frac{\mathbf{x}_{N}}{2}} & {\text { if } j=N+1}\end{array}\right. \]
** The \( \mathcal{A}^{h} \) operator
   Implementation using ~numpy~
  #+ATTR_LATEX: :options fontsize=\scriptsize
   #+begin_src python :exports code
	 import numpy as np

	 # Modified trapezoidal integration
	 def modified_trapz(t_x):
		 """ Modified trapezoidal integration"""
		 # Pads a 0 at the start of an array
		 temp = np.pad(t_x, (1,0), 'constant', constant_values=(0,0))
		 # Using roll calculate the integral (ghost node of 0)
		 return 0.5*(temp + np.roll(temp, -1))

	 # data
	 a = np.tile(np.arange(5,), 10)
	 b = modified_trapz(a)
   #+end_src
* Interlude
** Some questions about the project
   1. Position-verlet timestepping
   2. Keeping track of nodal and elemental quantities
   3. Implementing contact as a damped linear spring-mass force
   4. Project 3 concepts
   5. Implement code in logical steps
   6. Make use of the resources given to you
* Differentiation
** Derivatives
   - Frequently we need to take derivatives of functions (sampled at
     unique points)
   - One simple yet effective approach is using *finite-difference* formulae
*** Linear combination
	- As differentiation (wrt to one independent variable) is a linear operator,
      we once again perform a linear weighted combination of few function values
	  \[ \frac{d f(x)}{d x} \approx \sum_{i=1}^{n} \omega_i f(x_i) \]
	- We can then play games with *nodes* (\(x_i\)) and *weights* (\(\omega_i\))
      \Rightarrow different finite difference formulae
** Example
   An example illustrating the simplest FD formula (recall the timestepping lecture)
*** First principles                                              :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:

	\[ f^{\prime}(x) = \lim_{h \to 0} \frac{f(x+h) - f(x) }{h}\]
	Finite differences stop before the limit is reached (i.e. they have finite
	\( h \) )
** Considerations for differentiation schemes?
   While designing differentiation schemes, you are concerned about
	 - Cost (i.e. function evaluations)
	 - Accuracy (truncation error, how convergent is your scheme)
	 - Round-off errors
	 - Both these relate to stability too...

   These issues are sometimes subtle (because of the nature of differentiation),
   and so we need to be careful...
** Schemes for first-order derivatives
   Using Taylor series expansion, you can obtain arbitrary-order derivatives
   with arbitrary-order convergence. Some examples to approximate \(
   \frac{df(x)}{dx}\) are shown below ( \(\delta\) represents discrete
   differences)
*** Forward differences                                           :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta f(x)}{\delta x} = \frac{f(x+h) - f(x)}{h}\]
*** Backward differences                                          :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta f(x)}{\delta x} = \frac{f(x) - f(x-h)}{h}\]
*** Centered differences                                          :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta f(x)}{\delta x} = \frac{f(x+h) - f(x-h)}{2h}\]

** Schemes for higher-order derivatives
   Examples for second order derivatives
*** Forward differences                                           :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta^2 f(x)}{\delta x^2} = \frac{f(x)-2f(x+h)+f(x+2h)}{1h^{2}} \]
*** Backward differences                                          :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta^2 f(x)}{\delta x^2} = \frac{f(x)-2f(x-h)+f(x-2h)}{1h^{2}} \]
*** Centered differences                                          :B_example:
	:PROPERTIES:
	:BEAMER_env: example
	:END:
	\[ \frac{\delta^2 f(x)}{\delta x^2} = \frac{f(x+h)-2f(x)+f(x-h)}{1h^{2}} \]
** What do these do?
*** More schemes                                                    :B_block:
	:PROPERTIES:
	:BEAMER_env: block
	:END:
	Take a look at [[http://web.media.mit.edu/~crtaylor/calculator.html][MIT Finite Difference Calculator]] (sympy also has this
	capability) and build your own schemes!
*** Local polynomial representations                                :B_block:
	:PROPERTIES:
	:BEAMER_env: block
	:END:
	Finite differences assume your function is locally a polynomial (order
	depending upon the order of the finite difference calculation) and takes
	derivatives of these polynomials...
*** Local polynomial representations                               :B_column:
	:PROPERTIES:
	:BEAMER_COL: 0.48
	:BEAMER_env: column
	:END:

	\tikz[baseline=-2]{\draw[color=metropolisblue, thick] (0,0)--(1,0);}
	\rightarrow Forward difference

	\tikz[baseline=-2]{\draw[color=scarlet, thick] (0,0)--(1,0);}
	\rightarrow Backward difference

	\tikz[baseline=-2]{\draw[color=royalblue, thick] (0,0)--(1,0);}
	\rightarrow Central difference
***                                                                :B_column:
	:PROPERTIES:
	:BEAMER_env: column
	:BEAMER_COL: 0.5
	:END:
   #+CAPTION: First derivative approximation
   # #+ATTR_LATEX: :width 1.0\textwidth
   # [[file:images/fdiff.jpg]]
	#+begin_export latex
	\begin{center}
		\begin{tikzpicture}[
		declare function={func(\x)=sin(deg(pi*\x));},
		declare function={funcder(\x)=pi*cos(deg(pi*\x));}]
		\begin{axis}%
			[grid=none,
			axis x line=bottom,
			axis y line=none,
			domain=1.45:1.57,
			xmin=1.47,
			xmax=1.56,
			ymax=-0.975,
			ymin=-1.005,
			ticks=none,
			height=1.0\textwidth,
			enlargelimits=false,
			clip=true,
			disabledatascaling
			]
			\addplot[smooth, very thick,
			color=metropolisorange]{func(x)} node[pos=0.1, above, anchor=south east]
			{{\scriptsize$f(x)$}};

			% Draw points
			\node (M) [circle, minimum size=5, inner sep=0, fill=metropolisorange]
			at (axis cs: 1.5, {func(1.5)}) {};
			\node (N) [circle, minimum size=5, inner sep=0, fill=metropolisorange]
			at (axis cs: 1.52, {func(1.52)}) {};
			\node (O) [circle, minimum size=5, inner sep=0, fill=metropolisorange]
			at (axis cs: 1.55, {func(1.55)}) {};

			% % Add trapezoid betewen 1.53 and 1.61 by first defining coordinates
			% % https://tex.stackexchange.com/a/324328
			% \path (M) + (axis cs: 0.0, \pgfkeysvalueof{/pgfplots/ymin}) coordinate (Mx);
			% \path (N) + (axis cs: 0.0, \pgfkeysvalueof{/pgfplots/ymin}) coordinate (Nx);

			% Add trapezoid betewen 1.53 and 1.61 by first defining coordinates
			% https://tex.stackexchange.com/a/324328
			\coordinate (Mx) at (axis cs: 1.5,\pgfkeysvalueof{/pgfplots/ymin});
			\coordinate (Nx) at (axis cs: 1.52,\pgfkeysvalueof{/pgfplots/ymin});
			\coordinate (Ox) at (axis cs: 1.55,\pgfkeysvalueof{/pgfplots/ymin});

			% Draw derivatve from yn to yn+1 first
			% 0.44 to 0.48
			\draw[color=metropolisblue, thick] (M) -- (N);
			\draw[color=scarlet, thick] (N) -- (O);
			\draw[color=royalblue, thick] (O) -- (M);

			% node[pos=0, below right, anchor=west]{{\scriptsize $y^n$}}
			% node[below right, anchor=north west]{{\scriptsize $y^{n+1}$}}
			% node[right, anchor=south west]{Estd.};

			% % Draw actual derivatve line
			% \addplot[color=royalblue, thick] coordinates
			% { (0.44, {func(0.46) - 0.02*funcder(0.46) }) (0.48,
			% {func(0.46) + 0.02*funcder(0.46)}) } node[above]{Actual};

			% Draw connections to ground now
			\draw[dashed] (M) -- (Mx) node [above left, anchor=south east]
			{{\scriptsize$x-h$}};
			\draw[dashed] (N) -- (Nx) node [above left, anchor=south east]
			{{\scriptsize$x$}};
			\draw[dashed] (O) -- (Ox) node [above left, anchor=south east]
			{{\scriptsize$x+h$}};

		\end{axis}
		\end{tikzpicture}
	\end{center}
	#+end_export
** How do these perform (accuracy) ?
   *DEMO* using calculation of \( \frac{df}{dx} \)
   - Order of accuracy depends upon the Taylor series representation (*Taylor
     theorem*)
   - For the same function evaluations i.e. if \( n \) is the number of points
     considered in our algorithm
	 - Quadrature is accurate to \( \order{h^{n+1}}\)
	 - Differentation is accurate to \( \order{h^{n-1}}\)
   - Centered difference algorithms usually have a bump in order of accuracy,
     for the same width of stencil
   - Lots of freedom to design own schemes...
** Round-off errors
*** Why discuss round-off errors?
	 - Round-off errors : errors in precisely representing numbers on a computer
	 - Finite precision effects were not important in quadrature, but are in
       differentation.
	 - *Why*? Numerical differentation is susceptible to:
	   - Noise amplification
	   - Cancellation errors (due to signs)
	   - And as we saw last slide, is less accurate than quadrature
*** Effect of round-off
	- If \( \epsilon \) is machine precision \( 2^{-52} \approx 10^{-16} \) in
      double precision we can show
	\[\frac{\delta f(x)}{\delta x} = \frac{f(x+h) - f(x)}{h} \approx
	f^{\prime}(x)  + \frac{h}{2}f^{\prime\prime}(x) + \frac{\epsilon \cdot
	f}{h} + \order{h^2} \]
** Caution!!!
   In an ideal world, we should not be taking derivatives of functions
   numerically:
   - Differentation is /unbounded/:
	 A function with small \( \norm{f}_{\infty} \) can have arbitrarily large \(
     \norm{f^{\prime}}_{\infty} \) *DEMO*
   - Differentiation amplifies noise:
	 Smooth function with small, high-frequency wiggles (common in experiments
     and under-resolved simulations) can explode *DEMO*
   - Numerical differentiation : subject to cancellation and round-off errors *DEMO*
** Soft mechanics framework
   Many spatial differentiations. More explicitly,

   \[ \spot<2>{\begin{aligned}
   m_i \cdot \frac{\partial \mathbf{v}_i}{\partial t} &= \Delta^h
   \left(\frac{\mathbf{Q}_i^T\hat{\mathbf{S}}_i\boldsymbol{\sigma}^i_{\mathcal{L}}}{e_i}\right)
   +\mathbf{F}_i,\quad i=[1,n+1]
   \end{aligned}} \]
***                                                         :B_ignoreheading:
	:PROPERTIES:
	:BEAMER_env: ignoreheading
	:END:
	\[ \spot<3>{\begin{aligned}\frac{\hat{\mathbf{J}}_i}{e_i} \cdot \frac{\partial
	\boldsymbol{\omega}^i_{\mathcal{L}}}{\partial t} &=
	\Delta^h\left(\frac{\hat{\boldsymbol{\mathcal{B}}}_i\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^{i}}{\mathcal{E}_i^3}\right) +
	\mathcal{A}^h\left(\frac{\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i\times\hat{\boldsymbol{\mathcal{B}}}_i
	\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i}{\mathcal{E}_i^3}
	\hat{\mathcal{D}}_i\right) + \left(\mathbf{Q}_i\mathbf{t}_i\times\hat{\mathbf{S}}_i\boldsymbol{\sigma}^i_{\mathcal{L}}\right)\hat{\ell}_i\\
	&+ \mathbf{C}^i_{\mathcal{L}},\quad i=[1,n] \end{aligned}}\]

   # \[\begin{aligned} \frac{\hat{\mathbf{J}}_i}{e_i} \cdot \frac{\partial
   # \boldsymbol{\omega}^i_{\mathcal{L}}}{\partial t} &=
   # \Delta^h\left(\frac{\hat{\boldsymbol{\mathcal{B}}}_i\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^{i}}{\mathcal{E}_i^3}\right) +
   # \mathcal{A}^h\left(\frac{\hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i\times\hat{\boldsymbol{\mathcal{B}}}_i
   # \hat{\boldsymbol{\kappa}}_{\mathcal{L}}^i}{\mathcal{E}_i^3}
   # \hat{\mathcal{D}}_i\right) + \left(\mathbf{Q}_i\mathbf{t}_i\times\hat{\mathbf{S}}_i\boldsymbol{\sigma}^i_{\mathcal{L}}\right)\hat{\ell}_i\\
   # &+\left(\hat{\mathbf{J}}_i\cdot\frac{\boldsymbol{\omega}^i_{\mathcal{L}}}{e_i}\right)\times
   # \boldsymbol{\omega}^i_{\mathcal{L}} +
   # \frac{\hat{\mathbf{J}}_i\boldsymbol{\omega}^i_{\mathcal{L}}}{e_i^2}\cdot\frac{\partial
   # e_i}{\partial t}
   # + \mathbf{C}^i_{\mathcal{L}},\hspace{2.5cm}i=[1,n]
   # \end{aligned} \]
*** \(\Delta^{h} \) using finite differences                        :B_block:
	:PROPERTIES:
	:BEAMER_env: block
	:BEAMER_ACT: <3->
	:END:

** The \( \Delta^{h} \) operator
   Define the \( \Delta^{h} \) operator as:
   \[\mathbf{y}_{j=1, \ldots, N+1}=\Delta^{h}\left(\mathbf{x}_{i=1, \ldots,
   N}\right)=\left\{\begin{array}{ll}{\mathbf{x}_{1}} & {\text { if } j=1}
   \\ {\mathbf{x}_{j}-\mathbf{x}_{j-1}} & {\text { if } 1<j \leq N}
   \\ {-\mathbf{x}_{N}} & {\text { if } j=N+1}\end{array}\right. \]
** The \( \Delta^{h} \) operator
   Implementation using ~numpy~
  #+ATTR_LATEX: :options fontsize=\scriptsize
   #+begin_src python :exports code
	 import numpy as np

	 # Modified trapezoidal integration
	 def modified_diff(t_x):
		 """ Modified trapezoidal integration"""
		 # Pads a 0 at the end of an array
		 temp = np.pad(t_x, (0,1), 'constant', constant_values=(0,0))
		 # Using roll calculate the diff (ghost node of 0)
		 return (temp - np.roll(temp, 1))

	 # data
	 a = np.tile(np.arange(5,), 10)
	 b = modified_diff(a)
   #+end_src
** Credits
*** A good chunk of the material in these slides are taken from Prof. Andreas Kloeckner's CS450 lectures and Prof. Paul Fischer's TAM470 lectures
